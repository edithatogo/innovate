{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage of heartflow Library
",
    "
",
    "This notebook demonstrates the basic usage of the `heartflow` library for innovation and policy diffusion modeling. We will cover:
",
    "
",
    "1.  Fitting and predicting with single-product diffusion models (Bass, Gompertz, Logistic).
",
    "2.  Using the `ScipyFitter`.
",
    "3.  Demonstrating the `MultiProductDiffusionModel` with pre-defined parameters.
",
    "4.  Basic plotting of diffusion curves.
",
    "5.  Using preprocessing utilities for time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np
",
    "import pandas as pd
",
    "import matplotlib.pyplot as plt
",
    "
",
    "from heartflow.models.bass import BassModel
",
    "from heartflow.models.gompertz import GompertzModel
",
    "from heartflow.models.logistic import LogisticModel
",
    "from heartflow.models.competition import MultiProductDiffusionModel
",
    "from heartflow.fitters.scipy_fitter import ScipyFitter
",
    "from heartflow.utils.preprocessing import apply_stl_decomposition, cumulative_sum
",
    "from heartflow.plots import plot_diffusion_curve, plot_multi_product_diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single-Product Diffusion Models (Bass, Gompertz, Logistic)
",
    "
",
    "Let's create some synthetic data to demonstrate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for a diffusion curve
",
    "time_points = np.arange(1, 51) # 50 time points
",
    "true_p = 0.03
",
    "true_q = 0.3
",
    "true_m = 1000
",
    "
",
    "# Bass model cumulative function (for data generation)
",
    "def _bass_cumulative_true(t, p, q, m):
",
    "    exp_term = np.exp(-(p + q) * t)
",
    "    return m * (1 - exp_term) / (1 + (q / p) * exp_term)
",
    "
",
    "cumulative_adoptions = _bass_cumulative_true(time_points, true_p, true_q, true_m)
",
    "
",
    "# Add some noise
",
    "np.random.seed(42)
",
    "noise = np.random.normal(0, 20, len(time_points))
",
    "observed_adoptions = cumulative_adoptions + noise
",
    "observed_adoptions[observed_adoptions < 0] = 0 # Ensure no negative adoptions
",
    "
",
    "# Ensure cumulative
",
    "observed_adoptions = np.maximum.accumulate(observed_adoptions)
",
    "
",
    "plt.figure(figsize=(10, 6))
",
    "plt.plot(time_points, observed_adoptions, 'o-', label='Observed Data')
",
    "plt.title('Synthetic Observed Diffusion Data')
",
    "plt.xlabel('Time')
",
    "plt.ylabel('Cumulative Adoptions')
",
    "plt.grid(True)
",
    "plt.legend()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bass_model = BassModel()
",
    "bass_model.fit(time_points, observed_adoptions)
",
    "
",
    "print("Fitted Bass Model Parameters:", bass_model.params_)
",
    "
",
    "bass_predictions = bass_model.predict(time_points)
",
    "bass_score = bass_model.score(time_points, observed_adoptions)
",
    "print(f"Bass Model R^2 Score: {bass_score:.4f}")
",
    "
",
    "plot_diffusion_curve(time_points, observed_adoptions, bass_predictions, 
",
    "                     title="Bass Model Fit")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gompertz Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gompertz_model = GompertzModel()
",
    "gompertz_model.fit(time_points, observed_adoptions)
",
    "
",
    "print("Fitted Gompertz Model Parameters:", gompertz_model.params_)
",
    "
",
    "gompertz_predictions = gompertz_model.predict(time_points)
",
    "gompertz_score = gompertz_model.score(time_points, observed_adoptions)
",
    "print(f"Gompertz Model R^2 Score: {gompertz_score:.4f}")
",
    "
",
    "plot_diffusion_curve(time_points, observed_adoptions, gompertz_predictions, 
",
    "                     title="Gompertz Model Fit")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticModel()
",
    "logistic_model.fit(time_points, observed_adoptions)
",
    "
",
    "print("Fitted Logistic Model Parameters:", logistic_model.params_)
",
    "
",
    "logistic_predictions = logistic_model.predict(time_points)
",
    "logistic_score = logistic_model.score(time_points, observed_adoptions)
",
    "print(f"Logistic Model R^2 Score: {logistic_score:.4f}")
",
    "
",
    "plot_diffusion_curve(time_points, observed_adoptions, logistic_predictions, 
",
    "                     title="Logistic Model Fit")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the `ScipyFitter`
",
    "
",
    "The `ScipyFitter` provides a unified interface for fitting models using `scipy.optimize.curve_fit`. For single-product models, it essentially wraps the model's own `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = ScipyFitter()
",
    "
",
    "re_bass_model = BassModel()
",
    "fitted_params_fitter = fitter.fit(re_bass_model, time_points, observed_adoptions)
",
    "
",
    "print("Fitted Bass Model Parameters (via ScipyFitter):", fitted_params_fitter)
",
    "
",
    "re_bass_predictions = re_bass_model.predict(time_points)
",
    "plot_diffusion_curve(time_points, observed_adoptions, re_bass_predictions, 
",
    "                     title="Bass Model Fit (via ScipyFitter)")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Product Diffusion Model
",
    "
",
    "The `MultiProductDiffusionModel` simulates the diffusion of multiple interacting products/policies. For Phase 1, we demonstrate its prediction capabilities with pre-defined parameters, as its fitting is more complex and will be fully implemented in later phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for two interacting products
",
    "p_vals = [0.02, 0.015]  # Intrinsic adoption rates for Prod1, Prod2
",
    "Q_matrix = [
",
    "    [0.3, 0.05],  # Q[0,0] = imitation for Prod1 from Prod1, Q[0,1] = imitation for Prod1 from Prod2
",
    "    [0.03, 0.25]   # Q[1,0] = imitation for Prod2 from Prod1, Q[1,1] = imitation for Prod2 from Prod2
",
    "]
",
    "m_vals = [1000, 800]  # Ultimate market potentials for Prod1, Prod2
",
    "product_names = ["Product A", "Product B"]
",
    "
",
    "multi_model = MultiProductDiffusionModel(p=p_vals, Q=Q_matrix, m=m_vals, names=product_names)
",
    "
",
    "# Predict over a longer time horizon
",
    "time_horizon = np.arange(1, 101)
",
    "multi_predictions_df = multi_model.predict(time_horizon)
",
    "
",
    "print("Multi-Product Model Predictions (first 5 rows):\n", multi_predictions_df.head())
",
    "
",
    "plot_multi_product_diffusion(multi_predictions_df, 
",
    "                             title="Multi-Product Diffusion Simulation",
",
    "                             xlabel="Time", ylabel="Cumulative Adoptions")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Utilities
",
    "
",
    "Demonstrates how to use `apply_stl_decomposition` for handling seasonality and `cumulative_sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data with seasonality and noise
",
    "dates = pd.date_range(start='2020-01-01', periods=120, freq='M') # 10 years of monthly data
",
    "base_trend = np.linspace(10, 1000, 120) # Increasing trend
",
    "seasonal_pattern = 100 * np.sin(np.linspace(0, 3 * 2 * np.pi, 120)) # 3 cycles over 10 years
",
    "random_noise = np.random.normal(0, 30, 120)
",
    "
",
    "raw_data = pd.Series(base_trend + seasonal_pattern + random_noise, index=dates)
",
    "raw_data[raw_data < 0] = 0
",
    "
",
    "plt.figure(figsize=(12, 6))
",
    "plt.plot(raw_data)
",
    "plt.title('Raw Data with Trend, Seasonality, and Noise')
",
    "plt.xlabel('Date')
",
    "plt.ylabel('Value')
",
    "plt.grid(True)
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply STL decomposition
",
    "# Assuming a yearly seasonality for monthly data, so period=12
",
    "trend, seasonal, resid = apply_stl_decomposition(raw_data, period=12)
",
    "
",
    "plt.figure(figsize=(12, 8))
",
    "plt.subplot(4, 1, 1)
",
    "plt.plot(raw_data)
",
    "plt.title('Original Series')
",
    "plt.subplot(4, 1, 2)
",
    "plt.plot(trend)
",
    "plt.title('Trend Component')
",
    "plt.subplot(4, 1, 3)
",
    "plt.plot(seasonal)
",
    "plt.title('Seasonal Component')
",
    "plt.subplot(4, 1, 4)
",
    "plt.plot(resid)
",
    "plt.title('Residual Component')
",
    "plt.tight_layout()
",
    "plt.show()
",
    "
",
    "print("\nFitting Bass model to the extracted trend component:")
",
    "bass_model_on_trend = BassModel()
",
    "bass_model_on_trend.fit(np.arange(len(trend)), trend.values)
",
    "print("Fitted Bass Model Parameters on Trend:", bass_model_on_trend.params_)
",
    "
",
    "trend_predictions = bass_model_on_trend.predict(np.arange(len(trend)))
",
    "plot_diffusion_curve(np.arange(len(trend)), trend.values, trend_predictions, 
",
    "                     title="Bass Model Fit on STL Trend Component")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate cumulative_sum
",
    "daily_adoptions = np.array([10, 15, 20, 25, 30, 35, 40, 45, 50])
",
    "cumulative = cumulative_sum(daily_adoptions)
",
    "print("Daily Adoptions:", daily_adoptions)
",
    "print("Cumulative Adoptions:", cumulative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}